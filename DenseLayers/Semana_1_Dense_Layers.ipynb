{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d87b7c9",
   "metadata": {},
   "source": [
    "# Tarea Semana 1 — Dense Layers \n",
    "**Equipo:** Alan De Loa, Leonardio Lopez, Isaac Zaragoza, Luis Diaz, Luis Guzman \n",
    "**Fecha:** 06-10-2025\n",
    "\n",
    "**Objetivo:** En esta tarea se busca construir y evaluar un modelo de Deep Learning basado en capas densas con el dataset de cancer de Mama. El objetivo principal es predecir si un tumor es benigno o maligno a partir de 30 caracteristicas numericas obtenidas por imagenes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdffb95",
   "metadata": {},
   "source": [
    "## 1) Introducción (5%)\n",
    "\n",
    "En este notebook modelamos un problema de clasificación binaria usando el dataset Breast Cancer. Este dataset se obtuvo de la libreria de scikit-learn, y muestra diferentes imagenes las cuales se analizan para la detecciones de tumores. Elegimos este dataset por ser tabular, limpio y apropiado para capas densas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44082ed0",
   "metadata": {},
   "source": [
    "## 2) Exploración, explicación y limpieza de datos (20%)\n",
    "\n",
    "**Fuente y contexto del dataset:**  \n",
    "El dataset utilizado proviene de la libreria `scikit-learn`. Este conjunto de datos esta basado en el **Wisconsin Breast Cancer Dataset**, el cual es ampliamente conocido para problemas de clasificacion binaria en el ambito medico.\n",
    "- La tarea es poder predecir si un tumor es maligno o benigno.\n",
    "- Se cuetan con 569 muestras de tumores.\n",
    "- Se tienen 30 caracteristicas numericas obtenidas de imagenes digitales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f821816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    classification_report, roc_auc_score, confusion_matrix\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Reproducibilidad\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Utilidad para mostrar separadores bonitos en salidas de consola\n",
    "def banner(text):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(text)\n",
    "    print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40359e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga del dataset\n",
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target  # 0=maligno, 1=benigno\n",
    "\n",
    "banner(\"Vista general del DataFrame\")\n",
    "print(\"Shape (instancias, columnas):\", df.shape)   \n",
    "display(df.head(3))\n",
    "\n",
    "banner(\"Información de tipos de datos\")\n",
    "print(df.info())\n",
    "\n",
    "banner(\"Verificación de nulos\")\n",
    "print(df.isnull().sum().sum(), \"valores nulos en total\")\n",
    "\n",
    "banner(\"Distribución de la variable objetivo (target: 0=maligno, 1=benigno)\")\n",
    "print(df['target'].value_counts())\n",
    "print(\"\\nProporción:\")\n",
    "print(df['target'].value_counts(normalize=True).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6320ce7e",
   "metadata": {},
   "source": [
    "Limpieza y Transformación\n",
    "- Datos faltantes: el dataset no contiene valores nulos (no se requiere imputación).\n",
    "- Escala: las características tienen escalas muy distintas, lo cual puede afectar la estabilidad del entrenamiento → **Estandarizaremos** con `StandardScaler` (media 0, desviación 1).\n",
    "- División estratificada: usaremos 80/20 con `stratify=y` para preservar la proporción de clases.\n",
    "- class_weight: compensará el leve desbalance en entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7bc993",
   "metadata": {},
   "source": [
    "## 3) Desarrollo del Modelo de Deep Learning (25%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd882ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar X, y\n",
    "X = df.drop(columns=['target']).values.astype('float32')  # (569, 30)\n",
    "y = df['target'].values                                   # (569,)\n",
    "\n",
    "# Split estratificado 80/20\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=SEED, stratify=y\n",
    ")\n",
    "\n",
    "# Escalado estándar (fit solo en train)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_raw).astype('float32')\n",
    "X_test  = scaler.transform(X_test_raw).astype('float32')\n",
    "\n",
    "banner(\"Shapes tras split y escalado\")\n",
    "print(\"X_train:\", X_train.shape, \"X_test:\", X_test.shape)\n",
    "print(\"y_train:\", y_train.shape, \"y_test:\", y_test.shape)\n",
    "\n",
    "# Pesos de clase (balanceo)\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train)\n",
    "class_weight_dict = {int(c): w for c, w in zip(classes, class_weights)}\n",
    "banner(\"Pesos de clase\")\n",
    "print(class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9794822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks compartidos\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=12, restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_on_plateau = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.5, patience=5, min_lr=1e-6, verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ff0afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_A(input_dim: int, seed: int = SEED) -> keras.Model:\n",
    "    \"\"\"\n",
    "    Configuración A (Baseline):\n",
    "    - Inicialización He + ReLU (estabilidad de gradientes)\n",
    "    - Regularización L2 + Dropout (evitar sobreajuste)\n",
    "    - Salida sigmoide (clasificación binaria)\n",
    "    - LR: Adam(1e-3) + ReduceLROnPlateau para evitar divergencia\n",
    "    \"\"\"\n",
    "    he = keras.initializers.HeNormal(seed=seed)\n",
    "    l2 = regularizers.l2(1e-4)\n",
    "\n",
    "    inputs = keras.Input(shape=(input_dim,), name=\"features\")\n",
    "    x = layers.Dense(64, activation=\"relu\", kernel_initializer=he, kernel_regularizer=l2)(inputs)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    x = layers.Dense(32, activation=\"relu\", kernel_initializer=he, kernel_regularizer=l2)(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs, name=\"DenseBaseline_A\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[keras.metrics.BinaryAccuracy(name=\"acc\"),\n",
    "                 keras.metrics.AUC(name=\"auc\")]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model_A = build_model_A(X_train.shape[1])\n",
    "\n",
    "history_A = model_A.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop, reduce_on_plateau],\n",
    "    class_weight=class_weight_dict,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "banner(\"Entrenamiento finalizado: Modelo A\")\n",
    "print(\"Últimas métricas val:\", {k: v[-1] for k, v in history_A.history.items() if k.startswith(\"val_\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061e1931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_B(input_dim: int, x_train_len: int, seed: int = SEED) -> keras.Model:\n",
    "    \"\"\"\n",
    "    Configuración B (más estable con normalización y enfriamiento coseno):\n",
    "    - BatchNormalization entre capas densas\n",
    "    - CosineDecay para LR (enfriamiento coseno)\n",
    "    - Regularización L2 + Dropout\n",
    "    \"\"\"\n",
    "    he = keras.initializers.HeNormal(seed=seed)\n",
    "    l2 = regularizers.l2(1e-4)\n",
    "\n",
    "    # Pasos aproximados para CosineDecay (asumiendo 200 épocas y batch 32, 80% de train para entrenamiento interno)\n",
    "    steps_per_epoch = int(np.ceil(len(X_train) * 0.8 / 32))\n",
    "    total_steps = steps_per_epoch * 200\n",
    "    lr_schedule = keras.optimizers.schedules.CosineDecay(\n",
    "        initial_learning_rate=1e-3, decay_steps=total_steps\n",
    "    )\n",
    "\n",
    "    inputs = keras.Input(shape=(input_dim,))\n",
    "    x = layers.Dense(96, kernel_initializer=he, kernel_regularizer=l2)(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Dropout(0.30)(x)\n",
    "\n",
    "    x = layers.Dense(48, kernel_initializer=he, kernel_regularizer=l2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Dropout(0.30)(x)\n",
    "\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs, name=\"DenseCosine_B\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[keras.metrics.BinaryAccuracy(name=\"acc\"),\n",
    "                 keras.metrics.AUC(name=\"auc\")]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model_B = build_model_B(X_train.shape[1], len(X_train))\n",
    "\n",
    "history_B = model_B.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],  # CosineDecay ya ajusta LR\n",
    "    class_weight=class_weight_dict,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "banner(\"Entrenamiento finalizado: Modelo B\")\n",
    "print(\"Últimas métricas val:\", {k: v[-1] for k, v in history_B.history.items() if k.startswith(\"val_\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151535a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_of(history, metric):\n",
    "    vals = history.history.get(f\"val_{metric}\")\n",
    "    best = float(np.max(vals))\n",
    "    epoch = int(np.argmax(vals))\n",
    "    return best, epoch\n",
    "\n",
    "acc_A, ep_acc_A = best_of(history_A, \"acc\")\n",
    "auc_A, ep_auc_A = best_of(history_A, \"auc\")\n",
    "acc_B, ep_acc_B = best_of(history_B, \"acc\")\n",
    "auc_B, ep_auc_B = best_of(history_B, \"auc\")\n",
    "\n",
    "banner(\"Comparación de validación\")\n",
    "print(f\"Config A: best val_acc={acc_A:.4f} @epoch {ep_acc_A}, best val_auc={auc_A:.4f} @epoch {ep_auc_A}\")\n",
    "print(f\"Config B: best val_acc={acc_B:.4f} @epoch {ep_acc_B}, best val_auc={auc_B:.4f} @epoch {ep_auc_B}\")\n",
    "\n",
    "# Elegimos el mejor por AUC (más robusto cuando hay leves desbalances)\n",
    "best_model = model_A if auc_A >= auc_B else model_B\n",
    "best_name = \"A\" if best_model is model_A else \"B\"\n",
    "print(\"\\nMejor modelo por val_auc:\", best_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8ce7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción probabilidades y clases\n",
    "probs = best_model.predict(X_test).ravel()\n",
    "preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "# Métricas\n",
    "test_acc = np.mean(preds == y_test)\n",
    "test_auc = roc_auc_score(y_test, probs)\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "report = classification_report(y_test, preds, target_names=data.target_names)\n",
    "\n",
    "banner(\"Evaluación en Test\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test ROC-AUC:  {test_auc:.4f}\")\n",
    "print(\"\\nMatriz de confusión:\\n\", cm)\n",
    "print(\"\\nReporte de clasificación:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1ed390",
   "metadata": {},
   "source": [
    "\n",
    "### Curvas de entrenamiento\n",
    "Graficamos `loss`, `auc` y `accuracy` para comparar configuraciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949fed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, title):\n",
    "    # Loss\n",
    "    plt.figure()\n",
    "    plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.title(f\"{title} - Loss\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend(); plt.show()\n",
    "\n",
    "    # Accuracy\n",
    "    plt.figure()\n",
    "    plt.plot(history.history[\"acc\"], label=\"acc\")\n",
    "    plt.plot(history.history[\"val_acc\"], label=\"val_acc\")\n",
    "    plt.title(f\"{title} - Accuracy\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.legend(); plt.show()\n",
    "\n",
    "    # AUC\n",
    "    plt.figure()\n",
    "    plt.plot(history.history[\"auc\"], label=\"auc\")\n",
    "    plt.plot(history.history[\"val_auc\"], label=\"val_auc\")\n",
    "    plt.title(f\"{title} - AUC\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"AUC\"); plt.legend(); plt.show()\n",
    "\n",
    "plot_history(history_A, \"Modelo A\")\n",
    "plot_history(history_B, \"Modelo B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fb50c1",
   "metadata": {},
   "source": [
    "## Justificación de Decisiones de Diseño\n",
    "\n",
    "### 1️⃣ Función de costo\n",
    "- **Binary Cross-Entropy** fue utilizada porque el problema es de **clasificación binaria**.  \n",
    "  Esta función mide la discrepancia entre las probabilidades predichas y las etiquetas reales, penalizando fuertemente predicciones incorrectas con alta confianza.  \n",
    "\n",
    "### 2️⃣ Inicialización de pesos\n",
    "- Se usó **He Normal Initialization** para las capas con activación **ReLU**:\n",
    "  > “La inicialización He ajusta la varianza para evitar gradientes que desaparecen o explotan.”\n",
    "- La capa de salida usa **Glorot/Xavier** porque la activación `sigmoid` requiere una distribución más balanceada.\n",
    "\n",
    "### 3️⃣ Función de activación\n",
    "- **ReLU**: evita saturación (mitiga el problema de gradientes que desaparecen).\n",
    "- **Sigmoid** en salida: convierte la salida en probabilidad entre 0 y 1.\n",
    "\n",
    "### 4️⃣ Regularización\n",
    "- Se aplicaron dos técnicas complementarias:\n",
    "  - **L2 (weight decay)**: penaliza pesos grandes → evita sobreajuste.\n",
    "  - **Dropout (25–30%)**: desactiva aleatoriamente neuronas → fuerza robustez.\n",
    "\n",
    "### 5️⃣ Control de tasa de aprendizaje\n",
    "- En **Modelo A**, se usó **ReduceLROnPlateau**: reduce la tasa de aprendizaje automáticamente cuando `val_loss` deja de mejorar.\n",
    "- En **Modelo B**, se usó **CosineDecay**, una estrategia de “enfriamiento coseno” que reduce y aumenta ligeramente la tasa para explorar el espacio de parámetros con mayor estabilidad.\n",
    "\n",
    "### 6️⃣ Normalización de entradas\n",
    "- Se usó **StandardScaler** para llevar todas las características a una escala comparable.\n",
    "- Esto previene que características con magnitudes muy distintas dominen el cálculo de gradientes, lo que podría causar **divergencia numérica**.\n",
    "\n",
    "### 7️⃣ Métricas de evaluación\n",
    "- **Accuracy**: mide el desempeño global.\n",
    "- **AUC (Area Under the Curve)**: más sensible en datasets con leve desbalance; evalúa la capacidad de separación entre clases.  \n",
    "\n",
    "### 8️⃣ Estrategias contra la divergencia\n",
    "- **Escalado de datos + inicialización adecuada + control dinámico de la LR** garantizaron una convergencia suave.  \n",
    "- Las curvas de pérdida muestran descenso estable y sin oscilaciones fuertes, confirmando que las estrategias aplicadas (ReLU, He, LR decay, regularización) **previnieron la divergencia** del entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b274bbb2",
   "metadata": {},
   "source": [
    "## 4) Resultados e interpretación (25%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43132557",
   "metadata": {},
   "source": [
    "En este proyecto se entrenaron **dos configuraciones de redes neuronales densas** con distintos hiperparámetros\n",
    "(inicialización de pesos, regularización y estrategias de tasa de aprendizaje) para clasificar tumores como\n",
    "**malignos o benignos**.\n",
    "\n",
    "Tras comparar sus métricas de validación y prueba:\n",
    "\n",
    "- **Modelo A** (He + ReLU + L2 + Dropout + ReduceLROnPlateau) obtuvo mejor desempeño y mayor estabilidad de entrenamiento (val_AUC = 1.0, test_AUC = 0.9911).  \n",
    "- **Modelo B** (BatchNorm + CosineDecay) mostró buena convergencia temprana, pero menor val_loss y AUC ligeramente inferiores.\n",
    "\n",
    "**Interpretación de los resultados:**\n",
    "- El modelo logra una **separación casi perfecta** entre clases (AUC ≈ 0.99).  \n",
    "- Solo presenta **4 falsos negativos**, manteniendo alta sensibilidad para casos malignos.  \n",
    "- Las curvas de pérdida y precisión confirman una **convergencia suave sin divergencia**.\n",
    "\n",
    "**Justificación del modelo final seleccionado:**\n",
    "Se eligió el **Modelo A** porque:\n",
    "1. La combinación de **He initialization + ReLU** mantiene gradientes estables (evita desvanecimiento o explosión).  \n",
    "2. La regularización **L2 + Dropout** mejora la generalización.  \n",
    "3. **ReduceLROnPlateau** permite ajustar dinámicamente la tasa de aprendizaje evitando oscilaciones (divergencia).  \n",
    "4. La métrica **AUC** fue priorizada sobre la precisión global, al ser más robusta en problemas con leve desbalance y donde la clase “maligno” tiene mayor impacto clínico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803fd564",
   "metadata": {},
   "source": [
    "## 5) Conclusión (5%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fd6481",
   "metadata": {},
   "source": [
    "En este notebook se desarrolló un flujo completo de trabajo en Deep Learning para la **clasificación de cáncer de mama** utilizando el dataset de `scikit-learn`.  \n",
    "A lo largo del proceso se aplicaron los conceptos teóricos vistos en clase, desde la exploración y limpieza de datos hasta la implementación y evaluación de modelos neuronales.\n",
    "\n",
    "1. **Exploración y Preparación de Datos:**  \n",
    "   Se analizaron 569 instancias y 30 características numéricas sin valores nulos.  \n",
    "   Los datos fueron **escalados con StandardScaler** para garantizar estabilidad numérica y una convergencia adecuada durante el entrenamiento.\n",
    "\n",
    "2. **Desarrollo del Modelo:**  \n",
    "   Se entrenaron dos configuraciones de **redes neuronales densas** con diferentes estrategias de inicialización, regularización y control de tasa de aprendizaje.  \n",
    "   - **Modelo A:** Inicialización *He Normal*, activación *ReLU*, regularización *L2 + Dropout*, optimizador *Adam* con *ReduceLROnPlateau*.  \n",
    "   - **Modelo B:** Incorporó *Batch Normalization* y *CosineDecay* como ajuste dinámico de la tasa de aprendizaje.\n",
    "\n",
    "3. **Resultados:**  \n",
    "   Ambos modelos lograron un desempeño sobresaliente, pero el **Modelo A** destacó con:  \n",
    "   - **Accuracy (test):** 94.7%  \n",
    "   - **AUC (test):** 0.9911  \n",
    "   - Curvas de pérdida y precisión estables, sin señales de divergencia.  \n",
    "\n",
    "4. **Interpretación:**  \n",
    "   El modelo logró **alta capacidad de generalización** y excelente separación entre clases.  \n",
    "   Los pocos falsos negativos indican buena sensibilidad, aspecto crucial en aplicaciones médicas.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3037e9ce",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Orden y buenas prácticas (20%)\n",
    "\n",
    "- Todo el **contexto** y las **explicaciones** están en **Markdown**.  \n",
    "- El **código** está **comentado** en las celdas (con `# ...`).  \n",
    "- El notebook está **limpio** y **ordenado**, con secciones que siguen la **rúbrica**.  \n",
    "- Se probaron **múltiples configuraciones** y se **justificaron** las decisiones.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
